{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from algorithms.statics import *\n",
    "from algorithms.pkgs import CountVectorizer, MongoClient, re, defaultdict, stopwords, nltk\n",
    "client = MongoClient(DB_CONNECTION)\n",
    "sample_review = client.course_evals.entries.find_one()\n",
    "negatives = list(stopwords.words())[1509:1644] # SLICE ENGLISH STOPWORDS ONLY\n",
    "negatives.extend(CUSTOM_STOPWORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(raw_text):\n",
    "    text = ''\n",
    "    sent_tokenize = nltk.sent_tokenize(raw_text)\n",
    "    for s in sent_tokenize:\n",
    "        pattern = re.compile('[^a-zA-z\\s]+', re.UNICODE)\n",
    "        tmp = re.sub(pattern, ' ', s)\n",
    "        tmp = re.sub('\\s+', ' ', tmp)\n",
    "        text += ' < '+' '.join([x for x in nltk.word_tokenize(tmp)])+' > '\n",
    "    return text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSTRUCTOR NAMES\n",
    "sub_names = set()\n",
    "for entry in client.course_evals.entries.find():\n",
    "    for sub_name in entry['INSTRUCTOR_NAME'].split(', '):\n",
    "        if sub_name.lower() not in negatives:\n",
    "            sub_names.add(sub_name.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(entry):\n",
    "    vectorized = CountVectorizer(ngram_range=(N_GRAM_LOWER_LIM,N_GRAM_UPPER_LIM),stop_words=negatives)\n",
    "    example = tokenize(entry['RESPONSE_TEXT'])\n",
    "    inter = set(example.split(' ')).intersection(sub_names)\n",
    "    # REMOVE INSTRUCTOR NAMES\n",
    "    for sub_name in inter:\n",
    "        example = re.sub(sub_name, '', example)\n",
    "    example = re.sub('\\s+', ' ', example)\n",
    "    X = vectorized.fit_transform(raw_documents=[example])\n",
    "    return (X.toarray()[0].tolist(), vectorized.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_to_corpus = defaultdict(lambda:defaultdict(int))\n",
    "counter = 0\n",
    "for entry in client.course_evals.entries.find():\n",
    "    counter += 1\n",
    "    print(counter)\n",
    "    try:\n",
    "        res = vectorize(entry)\n",
    "        for freq,gram in zip(res[0],res[1]):\n",
    "            class_to_corpus[entry['COURSE_UNIQUE_ID']][gram] += freq\n",
    "    except ValueError:\n",
    "        print('stopwords only ... deleting from db')\n",
    "        client.course_evals.entries.delete_one({'_id':entry['_id']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W21-SURG-241-01/W21-ARTSTUDI-139-01\n",
      "[('anatomy', 5), ('class', 5), ('facial', 4), ('classes', 4), ('drawing', 3)]\n",
      "W21-COMPMED-200-01\n",
      "[('presentation', 2), ('professor', 2), ('questions', 2), ('scientific', 2), ('skills', 1)]\n",
      "W21-CHPR-200-01\n",
      "[('research', 9), ('different', 6), ('guest', 4), ('prevention', 4), ('class', 3)]\n",
      "W21-NENS-204-01\n",
      "[('neurologist', 1), ('think', 1), ('strokes', 1), ('want', 1), ('topics', 1)]\n",
      "W21-ORTHO-270-01\n",
      "[('engineering', 2), ('research', 2), ('tissue', 2), ('advances', 1), ('cell', 1)]\n",
      "W21-SURG-101-01\n",
      "[('online', 25), ('class', 20), ('anatomy', 17), ('lab', 16), ('lectures', 16)]\n",
      "W21-MED-221-01/W21-MED-121-01\n",
      "[('research', 10), ('translational', 6), ('class', 4), ('medical', 3), ('recommend', 3)]\n",
      "W21-PSYC-60N-01\n",
      "[('class', 27), ('life', 25), ('course', 11), ('definitely', 8), ('happiness', 8)]\n",
      "W21-BIOMEDIN-224-01/W21-GENE-224-01\n",
      "[('pharmacogenomics', 4), ('understanding', 2), ('get', 2), ('analysis', 1), ('medicine', 1)]\n",
      "W21-MED-73N-01\n",
      "[('class', 10), ('science', 8), ('scientific', 8), ('course', 7), ('research', 5)]\n",
      "num_classes:  1739\n"
     ]
    }
   ],
   "source": [
    "for entry in client.course_evals.derivatives.ngrams.find()[:10]:\n",
    "    print(entry['course_id'])\n",
    "    print(sorted(entry['freq_to_gram_dict'].items(),key=lambda v:v[1],reverse=True)[:5])\n",
    "print('num_classes: ', len(class_to_corpus.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save to DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.course_evals.derivatives.ngrams.drop()\n",
    "for key in class_to_corpus.keys():\n",
    "    document = {\n",
    "        'course_id': key,\n",
    "        'freq_to_gram_dict': class_to_corpus[key]\n",
    "        }\n",
    "    client.course_evals.derivatives.ngrams.insert_one(document)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e26b637a11847d2e70dc04358940328c2300e72eb7b7e7497ac9f2ea30305527"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('nlp-proj': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
